{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8b98b9776be4d44a573f99e1a7aa0d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8bf444732b245a6b82a7fd442eb4d2b",
              "IPY_MODEL_4ef6ec84d847476bb97f7d6ac215f6e9",
              "IPY_MODEL_52472e860ab84bcba5c6c3c243458e66"
            ],
            "layout": "IPY_MODEL_e18c5306051d40ab8751defc092ddca8"
          }
        },
        "d8bf444732b245a6b82a7fd442eb4d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd2c35d8a819488a8c78f12aafc0468e",
            "placeholder": "​",
            "style": "IPY_MODEL_b10bac31ce4e4118a74f667910fb6d8b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4ef6ec84d847476bb97f7d6ac215f6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3864a46b76e43b98fae35b5789afc6e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec5570a1de3f4d59a6f1f24e604cc471",
            "value": 2
          }
        },
        "52472e860ab84bcba5c6c3c243458e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee2b9d53e8c4af2b8196fcb7f18331b",
            "placeholder": "​",
            "style": "IPY_MODEL_7b2d4c8910ae40509f91c252d76fe219",
            "value": " 2/2 [01:24&lt;00:00, 39.58s/it]"
          }
        },
        "e18c5306051d40ab8751defc092ddca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd2c35d8a819488a8c78f12aafc0468e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b10bac31ce4e4118a74f667910fb6d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3864a46b76e43b98fae35b5789afc6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec5570a1de3f4d59a6f1f24e604cc471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ee2b9d53e8c4af2b8196fcb7f18331b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b2d4c8910ae40509f91c252d76fe219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"Where did Grandma take Emily?\",\n",
        "    \"What was inside the envelope?\",\n",
        "    \"Who is Thomas?\",\n",
        "    \"What did Thomas and Grandma do together?\",\n",
        "    \"What is Valentine's Day about, according to Grandma Rose?\",\n",
        "    \"what did gradma give to emily?\"\n",
        "]"
      ],
      "metadata": {
        "id": "0NCvnrpqe0i1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes\n",
        "!pip install langchain_community\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install accelerate\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "cM2D6tDAsudk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from huggingface_hub import login\n",
        "import torch\n",
        "import transformers\n",
        "from typing import Dict, List\n",
        "import re\n",
        "from transformers import BitsAndBytesConfig\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from accelerate import dispatch_model\n",
        "\n",
        "\n",
        "\n",
        "# Log in using the environment variable\n",
        "login(token=(\"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\"))\n",
        "\n",
        "# Function to read text from a file\n",
        "def read_file_content(filepath):\n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return \"File not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "# Function to read text from a PDF file\n",
        "def read_pdf_content(filepath):\n",
        "    try:\n",
        "        import PyPDF2\n",
        "        with open(filepath, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text()\n",
        "            return text\n",
        "    except FileNotFoundError:\n",
        "        return \"File not found.\"\n",
        "    except ImportError:\n",
        "        return \"PyPDF2 library not found. Please install it using: !pip install PyPDF2\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "class MistralQABot:\n",
        "    def __init__(self, model_name: str = \"mistralai/Mistral-7B-Instruct-v0.1\"):\n",
        "\n",
        "\n",
        "\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        )\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name , device_map=\"auto\",quantization_config=quantization_config,cache_dir=\"./model_cache\" )\n",
        "\n",
        "    def format_prompt(self, question: str, context: str) -> str:\n",
        "        \"\"\"Format the input prompt for Mistral.\"\"\"\n",
        "        return f\"\"\"<s>[INST] Answer the following question based on the given context.\n",
        "        Provide a detailed and accurate response.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer: [/INST]\"\"\"\n",
        "\n",
        "    def generate_answer(self, prompt: str) -> str:\n",
        "        \"\"\"Generate an answer using the Mistral model.\"\"\"\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        outputs = self.model.generate(\n",
        "            inputs.input_ids,\n",
        "            max_length=1000,  # Adjust based on your needs\n",
        "            min_length=50,   # Encourage longer responses\n",
        "            temperature=0.7,  # Balance between creativity and accuracy\n",
        "            top_p=0.9,       # Nucleus sampling for more natural text\n",
        "            do_sample=True,\n",
        "            num_return_sequences=1,\n",
        "            pad_token_id=self.tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        return response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "    def answer_question(self, question: str, context: str) -> Dict[str, str]:\n",
        "\n",
        "        prompt = self.format_prompt(question, context)\n",
        "        answer = self.generate_answer(prompt)\n",
        "\n",
        "        return {\n",
        "            'question': question,\n",
        "            'answer': answer,\n",
        "            'confidence': 'Generated by Mistral'\n",
        "        }\n",
        "\n",
        "def process_questions(context: str, questions: List[str]) -> None:\n",
        "\n",
        "\n",
        "    chatbot = MistralQABot()\n",
        "\n",
        "    print(\"Processing questions using Mistral...\\n\")\n",
        "\n",
        "    for question in questions:\n",
        "        result = chatbot.answer_question(question, context)\n",
        "        print(f\"Question: {result['question']}\")\n",
        "        print(f\"Answer: {result['answer']}\")\n",
        "        print(\"-\" * 80 + \"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    choice = input(\"Press 1 for PDF, 2 for TXT, or 3 to type your context: \")\n",
        "\n",
        "    if choice == '1':\n",
        "        pdf_filepath = input(\"Enter the path to your PDF file: \")\n",
        "        context = read_pdf_content(pdf_filepath)\n",
        "    elif choice == '2':\n",
        "        txt_filepath = input(\"Enter the path to your TXT file: \")\n",
        "        context = read_file_content(txt_filepath)\n",
        "    elif choice == '3':\n",
        "        context = input(\"Enter your context: \")\n",
        "    else:\n",
        "        print(\"Invalid choice. Please enter 1, 2, or 3.\")\n",
        "        exit()\n",
        "\n",
        "    process_questions(context, questions)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689,
          "referenced_widgets": [
            "d8b98b9776be4d44a573f99e1a7aa0d8",
            "d8bf444732b245a6b82a7fd442eb4d2b",
            "4ef6ec84d847476bb97f7d6ac215f6e9",
            "52472e860ab84bcba5c6c3c243458e66",
            "e18c5306051d40ab8751defc092ddca8",
            "bd2c35d8a819488a8c78f12aafc0468e",
            "b10bac31ce4e4118a74f667910fb6d8b",
            "d3864a46b76e43b98fae35b5789afc6e",
            "ec5570a1de3f4d59a6f1f24e604cc471",
            "4ee2b9d53e8c4af2b8196fcb7f18331b",
            "7b2d4c8910ae40509f91c252d76fe219"
          ]
        },
        "id": "0cUVPsU8s_eW",
        "outputId": "084b0a5f-68cd-4695-ff70-732801962a46"
      },
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Press 1 for PDF, 2 for TXT, or 3 to type your context: 2\n",
            "Enter the path to your TXT file: /content/test context.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8b98b9776be4d44a573f99e1a7aa0d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing questions using Mistral...\n",
            "\n",
            "Question: Where did Grandma take Emily?\n",
            "Answer: Grandma took Emily up the creaky attic stairs.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Question: What was inside the envelope?\n",
            "Answer: Inside the envelope was a beautiful, hand-drawn Valentine's Day card with delicate lace edges that read: \"To my dearest Rose, Your smile brightens my days, Your laughter is my favorite melody, And you will always have my heart. Forever yours, Thomas.\"\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Question: Who is Thomas?\n",
            "Answer: Thomas was Emily's Grandma Rose's best friend when she was young. They lived in the same neighborhood and did everything together, including climbing trees, racing bicycles, and building snow forts in winter. The hand-drawn Valentine's Day card with delicate lace edges that Grandma Rose showed Emily was from Thomas, expressing his love and appreciation for her.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Question: What did Thomas and Grandma do together?\n",
            "Answer: Thomas and Grandma Rose did a variety of activities together as children, such as climbing trees, racing bicycles, and building snow forts in winter.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Question: What is Valentine's Day about, according to Grandma Rose?\n",
            "Answer: According to Grandma Rose, Valentine's Day is about love in all forms - family, friends, and special people who touch our hearts.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Question: what did gradma give to emily?\n",
            "Answer: Grandma Rose gave Emily a small, faded pink envelope containing a beautiful, hand-drawn Valentine's Day card with delicate lace edges. The card read:\n",
            "\n",
            "\"To my dearest Rose,\n",
            "Your smile brightens my days,\n",
            "Your laughter is my favorite melody,\n",
            "And you will always have my heart.\n",
            "Forever yours, Thomas.\"\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "        new_question = input(\"Do you have more questions? (yes/no): \")\n",
        "        if new_question.lower() == \"yes\":\n",
        "            x= input(\"Enter your question: \")\n",
        "            list1=['']\n",
        "            list1[0]=x\n",
        "            process_questions(context, list1)\n",
        "\n",
        "        else:\n",
        "            break\n"
      ],
      "metadata": {
        "id": "2-i4srz4tj6m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}